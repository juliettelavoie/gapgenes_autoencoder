{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to do: re run avgMap and gradient section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create map from bayesian decoder\n",
    "alway run Load New Data, Get Manifold, bayesian decoder and then the section that you want( wt, perturbative, hidden nodes space, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from neuralgregnet import tools\n",
    "from neuralgregnet.training import load_model\n",
    "import random\n",
    "cmap = plt.get_cmap(\"Paired\")\n",
    "import os\n",
    "from tensorflow.keras import backend as K\n",
    "from scipy.optimize import curve_fit\n",
    "import scipy.io\n",
    "import commonFunctions as cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load New Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=['Gt', 'Kni', 'Kr', 'Hb']\n",
    "cutNaN=35 # to avoid all the nan values\n",
    "offNaN=965\n",
    "positions=np.linspace(0,100,1000)\n",
    "positions=positions[cutNaN:offNaN]\n",
    "#load data\n",
    "SortData,sortAge=cf.loadGG(f=\"gap_data_raw_dorsal_wt.mat\",path=\"DataPetkova/Data/Gap/\",\n",
    "                positions=positions,ageSort=True, age1=40,age2=44,cutPos=False)\n",
    "#SortData,sortAge=cf.loadGG(f=\"gap_data_raw_dorsal_wt_time_series.mat\",path=\"DataPetkova/Data/Gap/\",\n",
    "                #positions=positions,ageSort=True, age1=20,age2=24,cutPos=False) # load this file if you need to go outside 38-48 min\n",
    "#plot one embryo\n",
    "for i,g in enumerate(genes):\n",
    "    plt.plot(positions[:], SortData[10,i,:].T,color=cmap(i/4), label=g)\n",
    "plt.xlabel(\"Positions (% of AP axis)\")\n",
    "plt.ylabel(\"Concentration\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "#load autoencoder\n",
    "aeM= load_model(\"networks/newWT2\")\n",
    "aeM.compile(optimizer=optimizers.Adam(lr=0.01),loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get Manifold (linear or autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define index of boundary of positions\n",
    "cut=cf.find_nearest(positions,10)\n",
    "off=cf.find_nearest(positions,90)\n",
    "#make manifold out of SortData \n",
    "#h1s,h2s: all the SortData transformed in hidden nodes space (pink). avg1,avg2: average of h1s,h2s(black)\n",
    "h1s,h2s,avg1,avg2=cf.makeManifold(SortData,cut=cut,off=off,linear=True,aeM=aeM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian posterior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#P({h_i}|x)\n",
    "def Phx(h1,h2,p): #p is position index\n",
    "    C= np.cov (h1s[:,p], h2s[:,p])\n",
    "    return np.exp(-chi2(h1,h2,p,C)/2.0)/np.sqrt(np.linalg.det(C)*(2*np.pi)**2)\n",
    "\n",
    "def chi2(h1,h2,p,C):#chi square\n",
    "    inverseC=np.linalg.inv(C)\n",
    "    return (((h1-avg1[p])*inverseC[0,0]*(h1-avg1[p])) +\n",
    "            ((h1-avg1[p])*inverseC[0,1]*(h2-avg2[p]))+\n",
    "            ((h2-avg2[p])*inverseC[1,0]*(h1-avg1[p])) +\n",
    "            ((h2-avg2[p])*inverseC[1,1]*(h2-avg2[p])))\n",
    "\n",
    "#test\n",
    "print(Phx(h1s[0,200], h2s[0,200], 200))#middle\n",
    "print(Phx(avg1[200], avg2[200], 200))#higest\n",
    "print(Phx(h1s[0,300], h2s[0,300], 200))#lowest\n",
    "\n",
    "Px=1/(off-cut)\n",
    "def Zfunc(h1,h2):\n",
    "    sum=0\n",
    "    for p in range(len(avg1)):\n",
    "        sum+= Phx(h1,h2,p)*Px\n",
    "    return sum\n",
    "#P(x|{h_i}) posterior\n",
    "def Pxh(x,h1,h2,Z):# x is position\n",
    "    p=cf.find_nearest(positions[cut:off],x)# find index corresponding to position x\n",
    "    return (Phx(h1,h2,p)*Px)/Z\n",
    "\n",
    "def gauss(x,x0,sig,a):#for fit\n",
    "    return a*np.exp(-(x-x0)**2/(2*sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for random one embryo 'embryo' with index 'where'\n",
    "\n",
    "where=435\n",
    "embryo=2\n",
    "plt.axvline(positions[cut +where], label=\"Real Position x\")\n",
    "#get hidden nodes from gap gene and autoencoder\n",
    "#get_middle_layer_output = K.function([aeM.layers[0].input],[aeM.layers[1].output])\n",
    "#inp=SortData[embryo,:,cut+where].reshape((1,4))\n",
    "#layer_output = get_middle_layer_output([inp])[0][0]\n",
    "\n",
    "# or linear\n",
    "layer_output=[SortData[embryo,2,cut+where]-SortData[embryo,0,cut+where],SortData[embryo,3,cut+where]-SortData[embryo,1,cut+where]]\n",
    "\n",
    "Z=Zfunc(layer_output[0],layer_output[1])\n",
    "row=[]\n",
    "#for each possible position x* (y), calculate the probability\n",
    "for y in positions[cut:off]:\n",
    "    row.append(Pxh(y, layer_output[0], layer_output[1],Z))\n",
    "plt.plot(positions[cut:off],row , marker=\".\",color=\"orange\", linestyle='none')   \n",
    "plt.xlabel(\"Position x*\")\n",
    "plt.ylabel(r\"$P(x^*|{h_i})$\")\n",
    "\n",
    "#fit a gaussian locally (width around the peak) ) on the curve\n",
    "argmax=np.argmax(row)\n",
    "width=40\n",
    "popt,pcov = curve_fit(gauss,positions[cut+argmax-width:cut+argmax+width],row[argmax-width:argmax+width], p0=[positions[cut+argmax],0.5, 1/(np.sqrt(2*np.pi*0.1**2))])\n",
    "plt.plot(positions[cut:off],gauss(positions[cut:off], popt[0],popt[1], popt[2]), color=\"red\", label=\"fit\")\n",
    "print(\"Standard deviation: \"+str(popt[1]))\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wt maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map for one embryo (same as previous cell, but for all positions x)\n",
    "embryo=18\n",
    "get_middle_layer_output = K.function([aeM.layers[0].input],[aeM.layers[1].output])\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob=[]# probability of being a position (2d array). This is the map.\n",
    "std=[]# std of fit\n",
    "errStd=[] #error on the fit for std\n",
    "\n",
    "for x in p: # iterate through all position\n",
    "    print(x)\n",
    "    x=int(x)\n",
    "    row=[]\n",
    "    #get hidden nodes for position x\n",
    "    #autoencoder\n",
    "    #inp=SortData[embryo,:,cut+x].reshape((1,4)) \n",
    "    #layer_output = get_middle_layer_output([inp])[0][0]\n",
    "    #OR\n",
    "    #linear\n",
    "    layer_output=[SortData[embryo,2,cut+x]-SortData[embryo,0,cut+x],SortData[embryo,3,cut+x]-SortData[embryo,1,cut+x]]\n",
    "    \n",
    "    #normalization\n",
    "    Z=Zfunc(layer_output[0],layer_output[1])\n",
    "    for y in p:#iterate through all the possible position x* \n",
    "        y=int(y)\n",
    "        row.append(Pxh(positions[cut:off][y], layer_output[0],layer_output[1],Z)) # calculate the probability of being at the position x*\n",
    "    #fit a gaussian locally\n",
    "    #\"\"\"\n",
    "    try:\n",
    "        argmax=np.argmax(row)\n",
    "        #handling edge cases\n",
    "        if argmax<40:\n",
    "            width=argmax\n",
    "        else:\n",
    "            width=40\n",
    "        if argmax<3:\n",
    "            popt,pcov = curve_fit(gauss,pos[:40],row[:40], p0=[pos[argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "        else:\n",
    "            popt,pcov = curve_fit(gauss,pos[argmax-width:argmax+width],row[argmax-width:argmax+width], p0=[pos[argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "    \n",
    "    except RuntimeError:\n",
    "        popt=[np.nan,np.nan]\n",
    "        print(\"Error - curve_fit failed\")\n",
    "    if (pcov[0,0] == np.nan) or (pcov[1,1] == np.nan)  or (pcov[1,1] >100) or (pcov[0,0]>100):\n",
    "        std.append(np.nan )\n",
    "        errStd.append(np.nan )\n",
    "        \n",
    "    else:    \n",
    "        std.append(abs(popt[1]))\n",
    "        errStd.append(np.sqrt(pcov[1,1]))\n",
    "    #\"\"\"\n",
    "    #add all prob for a x* for this x\n",
    "    prob.append(row)\n",
    "    \n",
    "prob=np.array(prob)\n",
    "\n",
    "\n",
    "conf=plt.contourf(pos,pos,prob.T,50,cmap='jet', extend='max')\n",
    "plt.colorbar(conf)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(pos, std, marker=\".\", linestyle=\"none\")\n",
    "plt.errorbar(pos, std, yerr=errStd, label=\"error of fit\", linestyle=\"none\", marker=\"+\")\n",
    "plt.xlabel(\"Positions\")\n",
    "plt.ylabel(\"Standard deviation\")\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "print(\"mean of std: \"+ str(np.nanmean(std)))\n",
    "print(\"mean of error on std: \"+ str(np.nanmean(errStd)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average map\n",
    "prob,std,sig=cf.makeAvgMap(SortData,Pxh,Zfunc,linear=True,meanErr=True, medianErr=True,cut=cut, off=off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"useful/linear/wt.npy\",prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot better\n",
    "#prob=np.load(\"useful/linear/wt.npy\") # instead of rerunning 2 cell above\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "print(len(pos), prob.shape)\n",
    "plt.figure(figsize=(6,5))\n",
    "conf=plt.contourf(pos,pos,prob.T, 50,cmap='jet')\n",
    "conf.cmap.set_over(\"red\")\n",
    "cb1=plt.colorbar(conf)\n",
    "cb1.ax.set_ylabel(r\"$P(x^*|{h_i})$\")\n",
    "plt.ylabel(\"x*\")\n",
    "plt.xlabel(\"x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# map at different time windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data15,sortAgeT=cf.loadGG(f=\"gap_data_raw_dorsal_wt_time_series.mat\",path=\"DataPetkova/Data/Gap/\",\n",
    "                positions=positions,ageSort=True, age1=13,age2=17,cutPos=False)\n",
    "#plot\n",
    "for i,g in enumerate(genes):\n",
    "    plt.plot(positions[:], data15[1,i,:].T,color=cmap(i/4), label=g)\n",
    "plt.xlabel(\"Positions (% of AP axis)\")\n",
    "plt.ylabel(\"Concentration\")\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#average map for different time windows (fig 6)\n",
    "prob15,std15,sig15=cf.makeAvgMap(data15,Pxh,Zfunc,linear=True,meanErr=False, medianErr=False,cut=cut,off=off)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Probability in manifold (hidden nodes) space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find position with the highest probability for all points in manifold space\n",
    "latentSpace=np.linspace(-1,1,100)#(0,1,100) #ae: 0,1 # linear: -1, 1\n",
    "prediction=[]# grid of predictions\n",
    "sigmas=[]#grid of sigmas\n",
    "#iterate through grid in latent space\n",
    "for h1 in latentSpace:\n",
    "    print(h1)\n",
    "    pred=[] # row of grid predictions\n",
    "    sig=[]# row of grid sigmas\n",
    "    for h2 in latentSpace:\n",
    "        row=[]\n",
    "        # for normalization\n",
    "        Z=Zfunc(h1,h2)\n",
    "        # for each point on grid, calculate probability of being at each point on AP axis\n",
    "        for p in positions[cut:off]:\n",
    "            row.append(Pxh(p, h1,h2,Z))\n",
    "        #select highest prob to make prediction of position on AP axis\n",
    "        where=positions[cut+np.argmax(row)]\n",
    "        pred.append(where)\n",
    "        #\"\"\"\n",
    "        #calculate precision with localized fit\n",
    "        try:\n",
    "            argmax=np.argmax(row)\n",
    "            #loacalized fit\n",
    "            if argmax<40:\n",
    "                width=argmax\n",
    "            else:\n",
    "                width=40\n",
    "             #edge case\n",
    "            if argmax<3:\n",
    "                popt,pcov = curve_fit(gauss,positions[cut:off][:40],row[:40], p0=[positions[cut:off][argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "            else:\n",
    "                popt,pcov = curve_fit(gauss,positions[cut:off][argmax-width:argmax+width],row[argmax-width:argmax+width], p0=[positions[cut:off][argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "\n",
    "        except RuntimeError:\n",
    "            popt=[np.nan,np.nan]\n",
    "            print(\"Error - curve_fit failed\")\n",
    "        #if fit failed\n",
    "        if (pcov[0,0] == np.nan) or (pcov[1,1] == np.nan)  or (pcov[1,1] >100) or (pcov[0,0]>100):\n",
    "            sig.append(np.nan )\n",
    "        else:    \n",
    "            sig.append(abs(popt[1]))\n",
    "        \n",
    "    sigmas.append(sig)\n",
    "    #\"\"\"\n",
    "    prediction.append(pred)\n",
    "    \n",
    "#plot all the predictions on the latent space\n",
    "prediction=np.array(prediction)\n",
    "sigmas=np.array(sigmas)\n",
    "plt.figure(figsize=(6,5))        \n",
    "conf=plt.contourf(latentSpace,latentSpace,prediction.T,50,cmap='jet')\n",
    "plt.colorbar(conf)\n",
    "plt.xlabel(r\"$h_1$\")\n",
    "plt.ylabel(r\"$h_2$\")\n",
    "plt.title(\"Prediction of Position\")\n",
    "#\"\"\"\n",
    "plt.figure(figsize=(6,5))\n",
    "conf=plt.contourf(latentSpace,latentSpace,sigmas.T,50,cmap='jet')\n",
    "plt.colorbar(conf)\n",
    "plt.xlabel(r\"$h_1$\")\n",
    "plt.ylabel(r\"$h_2$\")\n",
    "plt.title(\"Standard deviation of fit\")\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"useful/linear/manifoldSpaceSigma.npy\",sigmas)\n",
    "#np.save(\"useful/linear/manifoldSpace.npy\",prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot it better\n",
    "latentSpace=np.linspace(-1,1,100)\n",
    "levels = [0,0.25,0.5,0.75,1,1.25,1.5,1.75,2]\n",
    "sigmas=np.load(\"useful/linear/manifoldSpaceSigma.npy\")\n",
    "plt.figure(figsize=(7,5))\n",
    "prediction=np.load(\"useful/linear/manifoldSpace.npy\")\n",
    "prediction=np.array(prediction)\n",
    "conf=plt.contour(latentSpace,latentSpace,sigmas.T,levels,cmap='spring',extend='max')\n",
    "cb=plt.colorbar(conf)\n",
    "cb.set_label('Standard deviation of fit')\n",
    "conf1=plt.contourf(latentSpace,latentSpace,prediction.T,50,cmap='jet',vmin=10, vmax=90)\n",
    "cb1=plt.colorbar(conf1)\n",
    "cb1.set_label('Position Predicted')\n",
    "plt.xlabel(r\"$h_1$\")\n",
    "plt.ylabel(r\"$h_2$\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perturbative map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move by epsilon in the direction that will give the worst prediction\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob2=[]\n",
    "allMaps2=[]\n",
    "allWI2=[]\n",
    "epsilon=0.1\n",
    "#iterate through 1 embryos because all is too long\n",
    "for emb in range(18,19):#SortData.shape[0]):\n",
    "    print(emb)\n",
    "    allRow=[]\n",
    "    WI=[]\n",
    "    #iterate through all positions along AP axis x\n",
    "    for x in p:\n",
    "        print(x)\n",
    "        x=int(x)\n",
    "        #linear manifold\n",
    "        layer_output=[SortData[emb,2,cut+x]-SortData[emb,0,cut+x],SortData[emb,3,cut+x]-SortData[emb,1,cut+x]]\n",
    "        #4 posibilities\n",
    "        t1=[layer_output[0] +epsilon,layer_output[1] +epsilon]\n",
    "        t2=[layer_output[0] -epsilon,layer_output[1] -epsilon]\n",
    "        t3=[layer_output[0] +epsilon,layer_output[1] -epsilon]\n",
    "        t4=[layer_output[0] -epsilon,layer_output[1] +epsilon]\n",
    "\n",
    "        ts=[t1,t2,t3,t4]\n",
    "        predIndex=[]\n",
    "        rowTest=np.zeros((4,799))\n",
    "        count=0\n",
    "        for t in ts:\n",
    "            row=[]\n",
    "            #for normalization\n",
    "            Z=Zfunc(t[0],t[1])\n",
    "            #iterate through all possible pocition x*\n",
    "            for y in p:\n",
    "                y=int(y)\n",
    "                row.append(Pxh(positions[cut:off][y], t[0],t[1],Z))\n",
    "            predIndex.append(np.argmax(row))\n",
    "            rowTest[count]=row\n",
    "            count+=1\n",
    "        diff=[abs(x-pred) for pred in predIndex]\n",
    "        worstIndex=np.argmax(diff)\n",
    "        WI.append(worstIndex)\n",
    "        allRow.append(rowTest[worstIndex])\n",
    "    allMaps2.append(allRow)\n",
    "    allWI2.append(WI)\n",
    "#average all maps\n",
    "allMaps2=np.array(allMaps2)\n",
    "prob2=np.mean(allMaps2,axis=0)\n",
    "\n",
    "#plot map\n",
    "conf=plt.contourf(pos,pos,prob2.T, 50,cmap='jet', extend='max')#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "plt.colorbar(conf)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"useful/linear/pertubmapEps1Emb18.npy\",prob2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prob2=np.load(\"useful/linear/pertubmapEps1Emb18.npy\")\n",
    "plt.figure(figsize=(6,5))\n",
    "conf=plt.contourf(pos,pos,prob2.T, 50,cmap='jet', vmax=0.12, extend='max')#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "plt.colorbar(conf)\n",
    "plt.title(\"Perturbative map. Epsilon=0.1. Embryo 18.\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distribution of displacement epsilon vector\n",
    "plt.hist(allWI2)\n",
    "plt.title(\"Distribution of epsilon 0.1 vectors. 0++ 1-- 2+- 3-+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the perturbation\n",
    "epsilon=0.1\n",
    "pertAvg1=[]\n",
    "pertAvg2=[]\n",
    "for i in range(len(avg1)):\n",
    "    if allWI2[0][i]==0:\n",
    "        pertAvg1.append(avg1[i]+epsilon)\n",
    "        pertAvg2.append(avg2[i]+epsilon)\n",
    "    if allWI2[0][i]==1:\n",
    "        pertAvg1.append(avg1[i]-epsilon)\n",
    "        pertAvg2.append(avg2[i]-epsilon)\n",
    "    if allWI2[0][i]==2:\n",
    "        pertAvg1.append(avg1[i]+epsilon)\n",
    "        pertAvg2.append(avg2[i]-epsilon)\n",
    "    if allWI2[0][i]==3:\n",
    "        pertAvg1.append(avg1[i]-epsilon)\n",
    "        pertAvg2.append(avg2[i]+epsilon)\n",
    "\n",
    "latentSpace=np.linspace(-1,1,100)\n",
    "levels = [0,0.25,0.5,0.75,1,1.25,1.5,1.75,2]\n",
    "plt.figure(figsize=(7,5))\n",
    "prediction=np.load(\"useful/linear/manifoldSpace.npy\")\n",
    "prediction=np.array(prediction)\n",
    "conf1=plt.contourf(latentSpace,latentSpace,prediction.T,50,cmap='jet')\n",
    "cb1=plt.colorbar(conf1)\n",
    "cb1.set_label('Position Predicted')\n",
    "plt.plot(avg1,avg2, color=\"black\", label=\"Average manifold\")\n",
    "plt.xlabel(r\"$h_1$\")\n",
    "plt.ylabel(r\"$h_2$\")\n",
    "plt.plot(pertAvg1,pertAvg2,'.', color=\"black\",linestyle='none',label=\"Worst perturbation\")\n",
    "#plt.title(\"Prediction of Position\")\n",
    "plt.legend()\n",
    "plt.title(\"Pertubed manifold. Epsilon 0.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# gradient map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient of prediction map\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob=np.load(\"useful/linear/wt.npy\")\n",
    "gradient= np.gradient(prob.T)\n",
    "plt.figure(figsize=(6,5))\n",
    "gradient=np.array(gradient)\n",
    "conf=plt.contourf(pos,pos,gradient[0], 50,cmap='jet')#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "plt.colorbar(conf)\n",
    "plt.title(\"Gradient x\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove small gradient\n",
    "print(prob)\n",
    "print(\"x\")\n",
    "#\"\"\"\n",
    "for y in range(gradient[0].shape[0]):\n",
    "    for z in range(gradient[0].shape[1]):\n",
    "        if gradient[0][y][z]<1e-8:\n",
    "            gradient[0][y][z]=0\n",
    "for y in range(gradient[1].shape[0]):\n",
    "    for z in range(gradient[1].shape[1]):\n",
    "        if gradient[1][y][z]<1e-8:\n",
    "            gradient[1][y][z]=0\n",
    "#\"\"\"            \n",
    "print(gradient[1])\n",
    "print(\"y\")\n",
    "print(gradient[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the gradient\n",
    "plt.figure(figsize=(12,10))\n",
    "#plt.quiver(pos[::1000],pos[::1000],gradient[0][::1000],gradient[1][::1000], linewidth=0.0001)\n",
    "conf=plt.contourf(pos,pos,prob.T, 50,cmap='jet')#CAREFUL prob needs to be transposed\n",
    "plt.colorbar(conf)\n",
    "for ix,x in enumerate(pos[::40]):\n",
    "    for iy,y in enumerate(pos[::40]):\n",
    "        if gradient[0][40*iy][40*ix]==0 and gradient[1][40*iy][40*ix]==0:\n",
    "            plt.plot(x,y,'.',markersize=0.8,color='white')\n",
    "        #print(x,y)\n",
    "        #plt.quiver(x,y,gradient[0][ix][iy],gradient[1][ix][iy],color=\"white\",width=0.005, pivot=\"tip\")\n",
    "        plt.quiver(x,y,gradient[1][40*iy][40*ix],gradient[0][40*iy][40*ix],color=\"white\", pivot=\"middle\",width=0.005,angles= 'xy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gradient of manifold space\n",
    "latentSpace=np.linspace(-1,1,100)\n",
    "prediction=np.load(\"useful/linear/manifoldSpace.npy\")\n",
    "gradls=np.gradient(prediction.T)\n",
    "gradls=np.array(gradls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot manifold space gradient\n",
    "plt.figure(figsize=(12,10))\n",
    "conf1=plt.contourf(latentSpace,latentSpace,prediction.T,50,cmap='jet')\n",
    "cb1=plt.colorbar(conf1)\n",
    "cb1.set_label('Position Predicted')\n",
    "for ix,x in enumerate(latentSpace[::2]):\n",
    "    for iy,y in enumerate(latentSpace[::2]):\n",
    "        if gradls[0][2*iy][2*ix]==0 and gradls[1][2*iy][2*ix]==0:\n",
    "            plt.plot(x,y,'.',markersize=0.8,color='black')\n",
    "        plt.quiver(x,y,gradls[1][2*iy][2*ix],gradls[0][2*iy][2*ix],color=\"black\", pivot=\"middle\",width=0.002,angles= 'xy')\n",
    "        #print(x,y,ix,iy,gradls[1][2*iy][2*ix],gradls[0][2*iy][2*ix])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Map based on single hidden node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change in Phx1 and chi21 to h1s and avg1 to predict from h1\n",
    "def Phx1(h1,p): #p is position index\n",
    "    sig2=(np.std(h2s[:,p]))**2# change for h1s for pred with h1\n",
    "    return np.exp(-chi21(h1,p,sig2)/2.0)/np.sqrt(sig2*2*np.pi)\n",
    "\n",
    "def chi21(h1,p,sig2):#chi square\n",
    "    return ((h1-avg2[p])**2)/sig2# change for avg1 for pred with h1\n",
    "\n",
    "#test\n",
    "print(Phx1(h2s[0,200], 200))#middle\n",
    "print(Phx1(avg2[200], 200))#higest\n",
    "print(Phx1(h2s[0,300], 200))#lowest\n",
    "\n",
    "Px=1/(off-cut)\n",
    "def Zfunc1(h1):\n",
    "    sum=0\n",
    "    for p in range(len(avg1)):\n",
    "        sum+= Phx1(h1,p)*Px\n",
    "    return sum\n",
    "\n",
    "def Pxh1(x,h1,Z):# x is position\n",
    "    p=cf.find_nearest(positions[cut:off],x)\n",
    "    return (Phx1(h1,p)*Px)/Z\n",
    "\n",
    "def gauss(x,x0,sig,a):#for fit\n",
    "    return a*np.exp(-(x-x0)**2/(2*sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtData=SortData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build map\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob=[]\n",
    "sig=[]\n",
    "std=[]\n",
    "allMaps=[]\n",
    "\n",
    "#iterate through all embryos\n",
    "for emb in range(wtData.shape[0]):\n",
    "    print(emb)\n",
    "    allStd=[]\n",
    "    allSig=[]\n",
    "    allRow=[]\n",
    "    #iterate through all positions along AP axis x\n",
    "    for x in p:\n",
    "        x=int(x)\n",
    "        row=[]\n",
    "        #linear manifold\n",
    "        layer_output=[wtData[emb,2,cut+x]-wtData[emb,0,cut+x],wtData[emb,3,cut+x]-wtData[emb,1,cut+x]]\n",
    "        #for normalization\n",
    "        Z=Zfunc1(layer_output[1]) # change for index 0 for pred with h1\n",
    "        #iterate through all possible position x*\n",
    "        for y in p:\n",
    "            y=int(y)\n",
    "            row.append(Pxh1(positions[cut:off][y], layer_output[1],Z))# change for index 0 for pred with h1\n",
    "        allRow.append(row)     \n",
    "    allMaps.append(allRow)\n",
    "#average all maps    \n",
    "prob=np.mean(allMaps,axis=0)\n",
    "#plot map\n",
    "levels=[0,0.01,0.02,0.03,0.04,0.05,0.06,0.07,0.08]\n",
    "conf=plt.contourf(pos,pos,prob.T, levels,cmap='jet', extend='max')#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "plt.colorbar(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "conf=plt.contourf(pos,pos,prob.T, 50,cmap='jet')#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "plt.colorbar(conf)\n",
    "plt.title(\"Prediction from h2\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"useful/linear/predByH2.npy\",prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bio)",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
