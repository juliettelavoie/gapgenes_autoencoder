{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create mutant map from bayesian decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import optimizers\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "from neuralgregnet import tools\n",
    "from neuralgregnet.training import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "import scipy.io\n",
    "from scipy.optimize import curve_fit\n",
    "import commonFunctions as cf\n",
    "cmap = plt.get_cmap(\"Paired\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m=5 # choose which mutant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load WT data associated with the mutant ( genotype ==1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=['Gt', 'Kni', 'Kr', 'Hb']\n",
    "cutNaN=35 # to avoid all the nan values\n",
    "offNaN=965\n",
    "positions=np.linspace(0,100,1000)\n",
    "positions=positions[cutNaN:offNaN]\n",
    "path=\"DataPetkova/Data/Gap/\"\n",
    "files=[\"gap_data_raw_dorsal_wt_osk.mat\",\"gap_data_raw_dorsal_wt_etsl.mat\",\"gap_data_raw_dorsal_wt_bcdE1.mat\",\"gap_data_raw_dorsal_wt_bcd_tsl.mat\",\n",
    "      \"gap_data_raw_dorsal_wt_bcd_osk.mat\",\"gap_data_raw_dorsal_wt_bcd_only_germline_clones.mat\",\"gap_data_raw_dorsal_wt_bcd_nos_tsl.mat\"]\n",
    "name=['osk','etsl','bcdE1','bcd-tsl','bcd-osk','bcdGermline','bcd-nos-tsl']\n",
    "#choose mutant\n",
    "\n",
    "#load data\n",
    "wtData,sortAge=cf.loadGG(f=files[m],path=path,positions=positions,ageSort=True,\n",
    "                         age1=40,age2=44,cutPos=False, genotype=1)\n",
    "#plot\n",
    "for i,g in enumerate(genes):\n",
    "    plt.plot(positions[:], wtData[1,i,:].T,color=cmap(i/4), label=g)\n",
    "plt.xlabel(\"Positions (% of AP axis)\")\n",
    "plt.ylabel(\"Concentration\")\n",
    "plt.legend()\n",
    "\n",
    "#load autoencoder\n",
    "aeM= load_model(\"networks/newWT2\")\n",
    "aeM.compile(optimizer=optimizers.Adam(lr=0.01),loss=\"mse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load mutant data associated with the mutant ( genotype ==2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(name[m])\n",
    "mutantData,sortAgeM=cf.loadGG(f=files[m],path=path,positions=positions,ageSort=True,\n",
    "                              age1=40,age2=44,cutPos=False, genotype=2)\n",
    "#plot\n",
    "for i,g in enumerate(genes):\n",
    "    plt.plot(positions[:], mutantData[1,i,:].T,color=cmap(i/4), label=g)\n",
    "plt.xlabel(\"Positions (% of AP axis)\")\n",
    "plt.ylabel(\"Concentration\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get manifold of wt( linear or autoencoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cut=cf.find_nearest(positions,10)\n",
    "off=cf.find_nearest(positions,90)\n",
    "h1s,h2s,avg1,avg2=cf.makeManifold(wtData,cut=cut,off=off,linear=True,aeM=aeM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# bayesian decoder based on wt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building the bayesian probability function\n",
    "avg=[avg1,avg2]\n",
    "hs=np.stack((h1s,h2s),axis=1)\n",
    "print(hs.shape)\n",
    "\n",
    "def Phx(h1,h2,p): #p is position index\n",
    "    #C= np.cov (h1s[:,p], h2s[:,p])\n",
    "    C=np.zeros((2,2))\n",
    "    for i in range(2):\n",
    "        for j in range(2):\n",
    "            C[i][j]=np.mean([(x[i][p]-avg[i][p])*(x[j][p]-avg[j][p]) for x in hs])\n",
    "            C[j][i]=C[i][j]\n",
    "    return np.exp(-chi2(h1,h2,p,C)/2.0)/np.sqrt(np.linalg.det(C)*(2*np.pi)**2)\n",
    "\n",
    "def chi2(h1,h2,p,C): \n",
    "    inverseC=np.linalg.inv(C)\n",
    "    return (((h1-avg1[p])*inverseC[0,0]*(h1-avg1[p])) +\n",
    "            ((h1-avg1[p])*inverseC[0,1]*(h2-avg2[p]))+\n",
    "            ((h2-avg2[p])*inverseC[1,0]*(h1-avg1[p])) +\n",
    "            ((h2-avg2[p])*inverseC[1,1]*(h2-avg2[p])))\n",
    "\n",
    "\n",
    "#test\n",
    "print(Phx(h1s[0,200], h2s[0,200], 200))#middle\n",
    "print(Phx(avg1[200], avg2[200], 200))#higest\n",
    "print(Phx(h1s[0,300], h2s[0,300], 200))#lowest\n",
    "\n",
    "Px=1/(off-cut)\n",
    "def Zfunc(h1,h2):\n",
    "    sum=0\n",
    "    for p in range(len(avg1)):\n",
    "        sum+= Phx(h1,h2,p)*Px\n",
    "    return sum\n",
    "\n",
    "def Pxh(x,h1,h2,Z):# x is position\n",
    "    p=cf.find_nearest(positions[cut:off],x)\n",
    "    return (Phx(h1,h2,p)*Px)/Z\n",
    "\n",
    "def gauss(x,x0,sig,a):  #use to fit later\n",
    "    return a*np.exp(-(x-x0)**2/(2*sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#map for one embryo\n",
    "embryo=1\n",
    "get_middle_layer_output = K.function([aeM.layers[0].input],[aeM.layers[1].output])\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob=[]# probability of being a position (2d array). This is the map.\n",
    "for x in p:\n",
    "    print(x)\n",
    "    x=int(x)\n",
    "    row=[]\n",
    "    #get hidden nodes of mutant data for position x\n",
    "    inp=mutantData[embryo,:,cut+x].reshape((1,4))\n",
    "    layer_output = get_middle_layer_output([inp])[0][0]\n",
    "    #normalization\n",
    "    Z=Zfunc(layer_output[0],layer_output[1])\n",
    "    for y in p:#iterate through all the possible position x* \n",
    "        y=int(y)\n",
    "        row.append(Pxh(positions[cut:off][y], layer_output[0],layer_output[1],Z)) # calculate the probability of being at the position x*\n",
    "   \n",
    "    prob.append(row)\n",
    "    \n",
    "prob=np.array(prob)\n",
    "\n",
    "\n",
    "conf=plt.contourf(pos,pos,prob.T,cmap='jet')\n",
    "plt.colorbar(conf)\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob,std,sig=cf.makeAvgMap(mutantData,Pxh,Zfunc,linear=True,meanErr=False, medianErr=False,cut=cut,off=off)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save(\"useful/linear/bcdGermline.npy\",prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#prob=np.load(\"useful/linear/osk.npy\")\n",
    "plt.figure(figsize=(6,5))\n",
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "conf=plt.contourf(pos,pos,prob.T, 50,cmap='jet', extend='max',vmax=0.04)\n",
    "conf.cmap.set_over(\"red\")\n",
    "cb1=plt.colorbar(conf)\n",
    "cb1.ax.set_ylabel(r\"$P(x^*|{h_i})$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproduce directly from 4 gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate average gap gene (useful for covariant matrix)\n",
    "avg1=np.mean(wtData[:,0,cut:off],axis=0)\n",
    "avg2=np.mean(wtData[:,1,cut:off],axis=0)\n",
    "avg3=np.mean(wtData[:,2,cut:off],axis=0)\n",
    "avg4=np.mean(wtData[:,3,cut:off],axis=0)\n",
    "avg=np.stack((avg1,avg2,avg3,avg4))\n",
    "print(avg4.shape,avg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#petkova's method\n",
    "\n",
    "def Phx4(g1,g2,g3,g4,p): #p is position index\n",
    "    #C= np.cov (np.stack((wtData[:,0,p], wtData[:,1,p],wtData[:,2,p],wtData[:,3,p]),axis=0))         \n",
    "    #\"\"\"\n",
    "    C=np.zeros((4,4))\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            C[i][j]=np.mean([(x[i][p]-avg[i][p])*(x[j][p]-avg[j][p]) for x in wtData])\n",
    "            C[j][i]=C[i][j]\n",
    "    #\"\"\"\n",
    "    return np.exp(-chi24(g1,g2,g3,g4,p,C)/2.0)/np.sqrt(np.linalg.det(C)*(2*np.pi)**4)\n",
    "\n",
    "def chi24(g1,g2,g3,g4,p,C):#chi square\n",
    "    inverseC=np.linalg.inv(C)\n",
    "    g=[g1,g2,g3,g4]\n",
    "    chi=0\n",
    "    for i in range(4):\n",
    "        for j in range(4):\n",
    "            chi+=(g[i]-avg[i][p])*inverseC[i][j]*(g[j]-avg[j][p])\n",
    "    return chi\n",
    "    \n",
    "print(Phx4(wtData[0,0,200], wtData[0,1,200],wtData[0,2,200],wtData[0,3,200], 200))\n",
    "print(Phx4(avg1[200], avg2[200],avg3[200],avg4[200], 200))\n",
    "print(Phx4(wtData[0,0,300], wtData[0,1,300],wtData[0,2,300],wtData[0,3,300], 200))\n",
    "\n",
    "Px=1/(off-cut)\n",
    "def Zfunc4(g1,g2,g3,g4):\n",
    "    sum=0\n",
    "    for p in range(len(avg1)):\n",
    "        sum+= Phx4(g1,g2,g3,g4,p)*Px\n",
    "    return sum\n",
    "\n",
    "def Pxh4(x,g1,g2,g3,g4,Z):\n",
    "    p=cf.find_nearest(positions[cut:off],x)\n",
    "    return (Phx4(g1,g2,g3,g4,p)*Px)/Z\n",
    "\n",
    "def gauss(x,x0,sig,a):\n",
    "    return a*np.exp(-(x-x0)**2/(2*sig**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p=np.linspace(0, off-cut-1 ,off-cut)\n",
    "pos=[positions[cut+int(x)] for x in p]\n",
    "prob=[]# 2d array of average probability of being a position. This is the prediction map.\n",
    "sig=[] #collecting the allSig for all embryos\n",
    "std=[]# collecting the allStd for all embryos\n",
    "allMaps=[] # collecting the allRows for all embryos. arrays for maps for each embryo.\n",
    "#iterate through all embryos\n",
    "for emb in range(mutantData.shape[0]):\n",
    "    print(emb)\n",
    "    allStd=[]#all std of fits\n",
    "    allSig=[]# all median sigma\n",
    "    allRow=[]# all rows of prediction along x*\n",
    "    #iterate through all positions along AP axis x\n",
    "    for x in p:\n",
    "        x=int(x)\n",
    "        row=[]\n",
    "        #for normalization\n",
    "        inp=mutantData[emb,:,cut+int(x)]\n",
    "        Z=Zfunc4(inp[0],inp[1],inp[2],inp[3])\n",
    "        #iterate through all possible position x*\n",
    "        for y in p:\n",
    "            y=int(y)\n",
    "            row.append(Pxh4(positions[cut:off][y], inp[0],inp[1],inp[2],inp[3],Z))\n",
    "        allRow.append(row)\n",
    "        #calculating positional error with fit like figure S5 of Petkova\n",
    "        try:\n",
    "            argmax=np.argmax(row)\n",
    "            #loacalized fit\n",
    "            if argmax<40:\n",
    "                width=argmax\n",
    "            else:\n",
    "                width=40\n",
    "             #edge case\n",
    "            if argmax<3:\n",
    "                popt,pcov = curve_fit(gauss,pos[:40],row[:40], p0=[pos[argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "            else:\n",
    "                popt,pcov = curve_fit(gauss,pos[argmax-width:argmax+width],row[argmax-width:argmax+width], p0=[pos[argmax],0.5, 1/(np.sqrt(2*np.pi*1**2))])\n",
    "\n",
    "        except RuntimeError:\n",
    "            popt=[np.nan,np.nan]\n",
    "            print(\"Error - curve_fit failed\")\n",
    "        #if fit failed\n",
    "        if (pcov[0,0] == np.nan) or (pcov[1,1] == np.nan)  or (pcov[1,1] >100) or (pcov[0,0]>100):\n",
    "            allStd.append(np.nan )\n",
    "        else:    \n",
    "            allStd.append(abs(popt[1]))\n",
    "        # other mesure of precision like  figure S1i\n",
    "        #median sigma\n",
    "        mu=np.sum([row[i]*pos[i] for i in range(len(pos))])\n",
    "        sigma=np.sqrt(np.sum([((pos[i]-mu)**2) * row[i] for i in range(len(pos))]))\n",
    "        allSig.append(sigma)\n",
    "\n",
    "    allStd=np.array(allStd)\n",
    "    std.append(np.nanmean(allStd))\n",
    "\n",
    "    allSig=np.array(allSig)\n",
    "    sig.append(np.nanmedian(allSig))\n",
    "\n",
    "    allMaps.append(allRow)\n",
    "#average all maps    \n",
    "prob=np.mean(allMaps,axis=0)\n",
    "\n",
    "print(\"mean std of localized fit\")\n",
    "print(np.nanmean(std))\n",
    "print(\"mean(over embryos) of median(over x) std of distributions\")\n",
    "print(np.nanmean(sig))\n",
    "#plot map\n",
    "plt.figure(figsize=(6,5))\n",
    "conf=plt.contourf(pos,pos,prob.T, 50,cmap='jet', extend='max',vmax=0.04)#CAREFUL prob needs to be transposed\n",
    "conf.cmap.set_over(\"red\")\n",
    "cb1=plt.colorbar(conf)\n",
    "cb1.ax.set_ylabel(r\"$P(x^*|{g_i})$\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"x*\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (bio)",
   "language": "python",
   "name": "bio"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
